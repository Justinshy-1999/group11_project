{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP7705 Project: (Re-)Imag(in)ing Price Trends\n",
    "\n",
    "This jupyter notebook is composed of 5 parts.\n",
    "\n",
    "1. Data processing\n",
    "2. Baseline model (including model construction, training and testing)\n",
    "3. Sensitivity analysis\n",
    "4. Grad-CAM\n",
    "5. Regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the file\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "extracted_dir = \"./\"\n",
    "with ZipFile('datagood.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_dir = \"./datagood/\"\n",
    "csv_file = \"labels.csv\"\n",
    "\n",
    "# Load the CSV data\n",
    "data_df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stock Code         0\n",
       "Year               0\n",
       "Month              0\n",
       "Label         189865\n",
       "Return             0\n",
       "Rise               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of missing values in each column\n",
    "data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create empty lists to store the image data and labels\n",
    "image_data = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through the CSV rows\n",
    "for index, row in data_df.iterrows():\n",
    "    stock_code = row[\"Stock Code\"]\n",
    "    year = row[\"Year\"]\n",
    "    month = row[\"Month\"]\n",
    "\n",
    "    # Construct the image filename\n",
    "    image_filename = f\"chart_{stock_code}_{year}_{month}.png\"\n",
    "    image_path = os.path.join(image_dir, image_filename)\n",
    "\n",
    "    # Open and convert the image to binary format\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((207, 101))\n",
    "    image = image.convert('L')\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    # Append the image data and label to the lists\n",
    "    image_data.append(image_array)\n",
    "    labels.append(row[\"Rise\"])\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "image_data = np.array(image_data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the data into training and testing sets (80:20 ratio)\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(image_data) * split_ratio)\n",
    "\n",
    "image_train_val_data = image_data[:split_index]\n",
    "label_train_val_data = labels[:split_index]\n",
    "image_test_data = image_data[split_index:]\n",
    "label_test_data = labels[split_index:]\n",
    "\n",
    "# Print the shape of the training and testing sets\n",
    "print(\"Training Images:\", image_train_val_data.shape)\n",
    "print(\"Training Labels:\", label_train_val_data.shape)\n",
    "print(\"Testing Images:\", image_test_data.shape)\n",
    "print(\"Testing Labels:\", label_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "data_df_temp = copy.deepcopy(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(['Label'], axis=1,inplace=True)\n",
    "data_df[\"Rise\"] = data_df[\"Rise\"].astype(int)\n",
    "data_df.rename(columns={'Rise':'Label'},inplace=True)\n",
    "data_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df_cp = data_df.copy()\n",
    "df_cp['Label'] = df_cp['Label'].replace({0: 'Positive', 1: 'Negative'})\n",
    "sns.set_palette(\"rocket\")\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "bar = sns.countplot(x=df_cp[\"Label\"],ax=ax)\n",
    "bar.set_title('Distribution of Positive Return and Negative', fontsize = 18, color = 'red')\n",
    "bar.set_xlabel('Return', fontsize = 13, color = 'blue')\n",
    "bar.set_ylabel('Count', fontsize = 13, color ='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of positive and negative returns\n",
    "positive_count = (df_cp[\"Return\"] >= 0).sum()\n",
    "negative_count = (df_cp[\"Return\"] < 0).sum()\n",
    "\n",
    "# Create a pie chart for positive and negative returns\n",
    "sizes = [negative_count, positive_count]\n",
    "labels = ['Negative Returns', 'Positive Returns']\n",
    "colors = ['green', 'darkred']\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.title(\"Distribution of Positive and Negative Returns\", fontsize=15, color='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cold_start = True\n",
    "\n",
    "if cold_start:\n",
    "  #image_train_val_data = np.concatenate(image_train_val_arr, 0)\n",
    "  image_train_val_data[image_train_val_data==255]=1\n",
    "  #label_train_val_data = np.concatenate(label_train_val_arr, 0)\n",
    "\n",
    "  image_train_data, image_val_data = image_train_val_data[:int(0.7*len(image_train_val_data))], image_train_val_data[int(0.7*len(image_train_val_data)):]\n",
    "  label_train_data, label_val_data = label_train_val_data[:int(0.7*len(label_train_val_data))], label_train_val_data[int(0.7*len(label_train_val_data)):]\n",
    "\n",
    "  np.save('train_x.npy', image_train_data)\n",
    "  np.save('train_y.npy', label_train_data)\n",
    "  np.save('val_x.npy', image_val_data)\n",
    "  np.save('val_y.npy', label_val_data)\n",
    "\n",
    "  #image_test_data = np.concatenate(image_test_arr, 0)\n",
    "  image_test_data[image_test_data==255]=1\n",
    "  #label_test_data = np.concatenate(label_test_arr, 0)\n",
    "\n",
    "  np.save('test_x.npy', image_test_data)\n",
    "  np.save('test_y.npy', label_test_data)\n",
    "\n",
    "else:\n",
    "  image_train_data = np.load(\"train_x.npy\")\n",
    "  image_val_data = np.load(\"val_x.npy\")\n",
    "  label_train_data = np.load(\"train_y.npy\")\n",
    "  label_val_data = np.load(\"val_y.npy\")\n",
    "  image_test_data = np.load(\"test_x.npy\")\n",
    "  label_test_data = np.load(\"test_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"The size of training image is \" + str(image_train_data.shape))\n",
    "print(\"The size of training label is \" + str(label_train_data.shape))\n",
    "print(\"The size of validation image is \" + str(image_val_data.shape))\n",
    "print(\"The size of validation label is \" + str(label_val_data.shape))\n",
    "print(\"The size of testing image is \" + str(image_test_data.shape))\n",
    "print(\"The size of testing label is \" + str(label_test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_file_path, label_file_path, binary=True):\n",
    "        self.data = np.load(data_file_path)\n",
    "        self.label = np.load(label_file_path)\n",
    "        self.binary = binary\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.label[index]\n",
    "        x = torch.from_numpy(x).float()\n",
    "        x = x.unsqueeze(0)\n",
    "        if self.binary:\n",
    "            y = np.where(y > 0, 1, 0)\n",
    "        y = torch.from_numpy(y).float()\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, data_file, label_file, binary=True):\n",
    "        self.data = data_file\n",
    "        self.label = label_file\n",
    "        self.binary = binary\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.label[index]\n",
    "        x = torch.from_numpy(x).float()\n",
    "        x = x.unsqueeze(0)\n",
    "        if self.binary:\n",
    "            y = np.where(y > 0, 1, 0)\n",
    "        y = torch.from_numpy(y).float()\n",
    "        return x,y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "class ConvNet(nn.Module):\n",
    "    \"\"\"Encoder for feature embedding\"\"\"\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(1, 64, kernel_size=(5,3), padding=(0, 1), stride=(1,1) ,dilation=(4,1)),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.LeakyReLU(0.01),\n",
    "                        nn.MaxPool2d(kernel_size  = (2, 1), stride=(2,1)))\n",
    "        nn.init.xavier_uniform_(self.layer1[0].weight)\n",
    "        self.layer2 = nn.Sequential(\n",
    "                        nn.Conv2d(64,128,kernel_size=(5,3),padding=(0,1), stride=(1,1), dilation=(1,1)),\n",
    "                        nn.BatchNorm2d(128),\n",
    "                        nn.LeakyReLU(0.01),\n",
    "                        nn.MaxPool2d(kernel_size  = (2, 1), stride=(2,1)),)\n",
    "        nn.init.xavier_uniform_(self.layer2[0].weight)\n",
    "        self.layer3 = nn.Sequential(\n",
    "                        nn.Conv2d(128,256,kernel_size=(5,3),padding=(0,1), stride=(1,1), dilation=(1,1)),\n",
    "                        nn.BatchNorm2d(256),\n",
    "                        nn.LeakyReLU(0.01),\n",
    "                        nn.MaxPool2d(kernel_size  = (2, 1), stride=(2,1)),)\n",
    "        nn.init.xavier_uniform_(self.layer3[0].weight)\n",
    "        self.layer4 = nn.Sequential(\n",
    "                        nn.Conv2d(256,512,kernel_size=(5,3),padding=(0,1), stride=(1,1), dilation=(1,1)),\n",
    "                        nn.BatchNorm2d(512),\n",
    "                        nn.LeakyReLU(0.01),\n",
    "                        nn.MaxPool2d(kernel_size  = (2, 1), stride=(2,1)),)\n",
    "        nn.init.xavier_uniform_(self.layer4[0].weight)\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(512*1*207, 2),  \n",
    "            nn.Dropout(p=0.5),  \n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.shape[0],-1)\n",
    "        result = self.fc1(out)\n",
    "        result = self.softmax(result)\n",
    "\n",
    "        return result\n",
    "\n",
    "def conv3():\n",
    "    return ConvNet()\n",
    "\n",
    "model = conv3()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model.to('cuda'), input_size=(1, 101, 207), device=\"cuda\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class Averager():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "        self.v = 0\n",
    "\n",
    "    def add(self, x):\n",
    "        self.v = (self.v * self.n + x) / (self.n + 1)\n",
    "        self.n += 1\n",
    "\n",
    "    def item(self):\n",
    "        return self.v\n",
    "\n",
    "\n",
    "def pretrain(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    ## training with ce\n",
    "    loss_avg = Averager() \n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        train_inputs, train_targets = batch[0], batch[1]\n",
    "        train_targets = train_targets.long()\n",
    "        train_inputs = train_inputs.to(device=device)\n",
    "        train_targets = train_targets.to(device=device)\n",
    "        train_logits = model(train_inputs)\n",
    "        loss = nn.CrossEntropyLoss()(train_logits, train_targets)\n",
    "        loss_avg.add(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Train Loss %.4f\" % (loss_avg.item()))\n",
    "    return loss_avg.item()\n",
    "\n",
    "def evaluate_batch(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct = num = 0\n",
    "    for iter, pack in enumerate(data_loader):\n",
    "        data, target = pack[0].to(device), pack[1].to(device)\n",
    "        targets = target.long()\n",
    "        logits = model(data)\n",
    "        _, pred = logits.max(1)\n",
    "        correct += pred.eq(target).sum().item()\n",
    "        num += data.shape[0]  \n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "    return correct/num\n",
    "\n",
    "\n",
    "def get_confusion(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct = num = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for iter, pack in enumerate(data_loader):\n",
    "        data, target = pack[0].to(device), pack[1].to(device)\n",
    "        targets = target.long()\n",
    "        logits = model(data)\n",
    "        _, pred = logits.max(1)\n",
    "        y_true.append(target.item())\n",
    "        y_pred.append(pred.item())\n",
    "        correct += pred.eq(target).sum().item()\n",
    "        num += data.shape[0]  \n",
    "    torch.cuda.empty_cache()\n",
    "    print(y_true)\n",
    "    print(y_pred)\n",
    "    model.train()\n",
    "    return confusion_matrix(y_true, y_pred)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import  os \n",
    "\n",
    "\n",
    "\n",
    "trainset = ImageDataset(\"train_x.npy\",\"train_y.npy\")\n",
    "valset = ImageDataset(\"val_x.npy\",\"val_y.npy\")\n",
    "\n",
    "batch_size = 1\n",
    "epoch = 15\n",
    "lr = 1e-3\n",
    "wd =  5e-4\n",
    "model_name = 'weight.pth'\n",
    "train_loader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True, num_workers=0,\n",
    "                pin_memory=True, drop_last=True)\n",
    "val_loader = DataLoader(dataset=valset, batch_size=batch_size, shuffle=False, num_workers=0,\n",
    "                pin_memory=True, drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "model = conv3().cuda()\n",
    "optimizer=torch.optim.AdamW(model.parameters(), lr, weight_decay=wd)\n",
    "evaluate_batch(model, val_loader, device)\n",
    "best_acc = 0\n",
    "count = 0\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for i in range(1, epoch+1):\n",
    "    print('Epoch : ', i)\n",
    "    train_loss = pretrain(model, train_loader, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    val_acc = evaluate_batch(model, val_loader, device)\n",
    "    valid_losses.append(1-val_acc)\n",
    "    print('Val Acc : ', val_acc)\n",
    "    if  best_acc < val_acc:\n",
    "        count = 0\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "    else:\n",
    "        count += 1\n",
    "    if count >= 4:\n",
    "        break\n",
    "\n",
    "\n",
    "# visualize the loss as the network trained\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,len(train_losses)+1),train_losses, label='Training Loss')\n",
    "plt.plot(range(1,len(valid_losses)+1),valid_losses,label='Validation Loss')\n",
    "\n",
    "# find position of lowest validation loss\n",
    "minposs = valid_losses.index(min(valid_losses))+1 \n",
    "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "# plt.ylim(0, 1) # consistent scale\n",
    "plt.xlim(0, len(train_losses)+1) # consistent scale\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('loss_plot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# 绘制混淆矩阵\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    Input\n",
    "    - cm : 计算出的混淆矩阵的值\n",
    "    - classes : 混淆矩阵中每一行每一列对应的列\n",
    "    - normalize : True:显示百分比, False:显示个数\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = ImageDataset(\"test_x.npy\",\"test_y.npy\")\n",
    "test_loader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=False, num_workers=0,\n",
    "                pin_memory=True, drop_last=True)\n",
    "test_acc = evaluate_batch(model, test_loader, device)\n",
    "print('Test Acc : ', test_acc)\n",
    "test_matrix = get_confusion(model, test_loader, device)\n",
    "classes = ['Positive', 'Negative']\n",
    "\n",
    "plot_confusion_matrix(test_matrix, classes=classes, normalize=False, title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad-CAM \n",
    "please first install the supporting pacakge:\n",
    "\n",
    "pip install grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install grad-cam\n",
    "from pytorch_grad_cam import GradCAM # or ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "epoch = 15\n",
    "lr = 1e-3\n",
    "wd =  5e-4\n",
    "\n",
    "train_x  = np.load(\"train_x.npy\")\n",
    "train_y = np.load(\"train_y.npy\")\n",
    "val_x , val_y = np.load(\"val_x.npy\"), np.load(\"val_y.npy\")\n",
    "trainset = ImgDataset(train_x , train_y )\n",
    "valset = ImgDataset(val_x , val_y)\n",
    "model_name = \"weight.pth\"\n",
    "train_loader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True, num_workers=0,\n",
    "                pin_memory=True, drop_last=True)\n",
    "val_loader = DataLoader(dataset=valset, batch_size=batch_size, shuffle=False, num_workers=0,\n",
    "                pin_memory=True, drop_last=True)\n",
    "\n",
    "print(valset)\n",
    "device = 'cuda'\n",
    "\n",
    "#load the trained model. Here we assume the weight has been saved\n",
    "model_name = \"weight.pth\"\n",
    "model = conv3()\n",
    "model.load_state_dict(torch.load(model_name,map_location=torch.device('cuda')))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find 5 images that are classified as 1 or 0\n",
    "\n",
    "\n",
    "classification_object = 1 # or let classification_object = 1 to get another bunch of images\n",
    "image_list = []\n",
    "label_list = []\n",
    "counter = 0\n",
    "# better shuffle the data loader\n",
    "for iter, pack in enumerate(val_loader):\n",
    "    data, target = pack[0].to(device), pack[1].to(device)\n",
    "    #targets = target.long()\n",
    "    logits = model(data)\n",
    "    _, pred = logits.max(1)\n",
    "    class_list = data[pred==classification_object,]\n",
    "    if class_list.size(0) > 0:\n",
    "        print(class_list)\n",
    "        obj = class_list[random.randrange(class_list.size(0)),]\n",
    "        counter = counter+1\n",
    "    image_list.append(obj)\n",
    "    if counter >= 5:\n",
    "        break\n",
    "\n",
    "image_list = torch.stack(image_list)\n",
    "\n",
    "\n",
    "input_tensors = image_list\n",
    "    \n",
    "\n",
    "# Create an input tensor image for your model..\n",
    "# Note: input_tensor can be a batch tensor with several images!\n",
    "\n",
    "# Construct the CAM object once, and then re-use it on many images:\n",
    "aug_smooth = True\n",
    "eigen_smooth = True\n",
    "\n",
    "\n",
    "target_layer_1 = [model.layer1[-1]]\n",
    "cam_1 = GradCAM(model=model, target_layers=target_layer_1, use_cuda=False)\n",
    "# You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "grayscale_cam_1 = cam_1(input_tensor=input_tensors, targets=None ,aug_smooth=aug_smooth,eigen_smooth=eigen_smooth)\n",
    "\n",
    "#visualization = show_cam_on_image(input_tensors, grayscale_cam, use_rgb=True)\n",
    "\n",
    "target_layer_2 = [model.layer2[-1]]\n",
    "cam_2 = GradCAM(model=model, target_layers=target_layer_2, use_cuda=False)\n",
    "# You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "grayscale_cam_2 = cam_2(input_tensor=input_tensors, targets=None ,aug_smooth=aug_smooth,eigen_smooth=eigen_smooth)\n",
    "\n",
    "\n",
    "target_layer_3 = [model.layer3[-1]]\n",
    "cam_3 = GradCAM(model=model, target_layers=target_layer_3, use_cuda=False)\n",
    "# You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "grayscale_cam_3 = cam_3(input_tensor=input_tensors, targets=None ,aug_smooth=aug_smooth,eigen_smooth=eigen_smooth)\n",
    "\n",
    "target_layer_4 = [model.layer4[-1]]\n",
    "cam_4 = GradCAM(model=model, target_layers=target_layer_4, use_cuda=False)\n",
    "# You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "grayscale_cam_4 = cam_4(input_tensor=input_tensors, targets=None ,aug_smooth=aug_smooth,eigen_smooth=eigen_smooth)\n",
    "\n",
    "camera = torch.cat((image_list[:,0,], torch.from_numpy(grayscale_cam_1),torch.from_numpy(grayscale_cam_2),torch.from_numpy(grayscale_cam_3),torch.from_numpy(grayscale_cam_4)),0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_cpu = image_list.cpu()\n",
    "grayscale_cam_1_cpu = grayscale_cam_1.cpu().numpy()\n",
    "grayscale_cam_2_cpu = grayscale_cam_2.cpu().numpy()\n",
    "grayscale_cam_3_cpu = grayscale_cam_3.cpu().numpy()\n",
    "grayscale_cam_4_cpu = grayscale_cam_4.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show multiple images\n",
    "camera = camera.cpu().numpy()\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "columns = 5\n",
    "rows = 4\n",
    "for i in range(0, columns*rows ):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.axis('off')\n",
    "    if i<= 4:\n",
    "        plt.imshow(camera[i,],cmap=\"gray\")\n",
    "    else:\n",
    "        plt.imshow(camera[i,],cmap=\"Blues_r\")\n",
    "plt.savefig('4x5.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
